{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5UV5Im06Qg7"
   },
   "source": [
    "## Environment set up and import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:34.144582Z",
     "iopub.status.busy": "2022-08-23T03:59:34.143917Z",
     "iopub.status.idle": "2022-08-23T03:59:34.169280Z",
     "shell.execute_reply": "2022-08-23T03:59:34.168126Z",
     "shell.execute_reply.started": "2022-08-23T03:59:34.144448Z"
    },
    "id": "b-0LJOu1Jumr",
    "outputId": "7fc4ad26-aae2-42e8-d56a-92e88a0c2e57"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:34.172512Z",
     "iopub.status.busy": "2022-08-23T03:59:34.171705Z",
     "iopub.status.idle": "2022-08-23T03:59:40.562093Z",
     "shell.execute_reply": "2022-08-23T03:59:40.560901Z",
     "shell.execute_reply.started": "2022-08-23T03:59:34.172466Z"
    },
    "id": "izI8Tcx5Sswy",
    "outputId": "a6446b8f-5e65-474b-bf91-62fc303df26b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "with tf.device(device_name):\n",
    "  print(device_name.split(\":\")[1],\" running . . . \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:40.564553Z",
     "iopub.status.busy": "2022-08-23T03:59:40.563861Z",
     "iopub.status.idle": "2022-08-23T03:59:40.570311Z",
     "shell.execute_reply": "2022-08-23T03:59:40.569190Z",
     "shell.execute_reply.started": "2022-08-23T03:59:40.564514Z"
    },
    "id": "BZNKon484KfJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:40.575572Z",
     "iopub.status.busy": "2022-08-23T03:59:40.575071Z",
     "iopub.status.idle": "2022-08-23T03:59:41.959346Z",
     "shell.execute_reply": "2022-08-23T03:59:41.958277Z",
     "shell.execute_reply.started": "2022-08-23T03:59:40.575530Z"
    },
    "id": "U7Vkit2dTCvS"
   },
   "outputs": [],
   "source": [
    "import os, keras, numpy,tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V1zVhkQ6V1P"
   },
   "source": [
    "## **Discriminator** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:41.963503Z",
     "iopub.status.busy": "2022-08-23T03:59:41.963195Z",
     "iopub.status.idle": "2022-08-23T03:59:42.560117Z",
     "shell.execute_reply": "2022-08-23T03:59:42.559040Z",
     "shell.execute_reply.started": "2022-08-23T03:59:41.963475Z"
    },
    "id": "13b25edNTGV5",
    "outputId": "c347d8ac-90f5-4c74-fc47-00fc968ac618"
   },
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(128,128,3),n_classes=7):\n",
    "\n",
    "    # input level\n",
    "    label_layer_1 = Input(shape=(1,), name = \"input_label\")\n",
    "    label_layer_2 = Embedding(n_classes, 200)(label_layer_1)\n",
    "    label_layer_3 = Dense(in_shape[0] * in_shape[1])(label_layer_2)\n",
    "    label_layer_4 = Reshape((in_shape[0], in_shape[1], 1))(label_layer_3)\n",
    "    # (128, 128, 1)\n",
    "\n",
    "    # input image\n",
    "    input_image = Input(shape=in_shape, name = \"input_image\")\n",
    "    # (128, 128, 3)\n",
    "\n",
    "    concat_layer = Concatenate()([input_image, label_layer_4])\n",
    "    # (128, 128, 4)\n",
    "\n",
    "    conv2d_layer_1 = Conv2D(filters = 16, kernel_size = (3,3), strides = (2,2), padding='same')(concat_layer)\n",
    "    conv2d_layer_1 = LeakyReLU(alpha=0.3)(conv2d_layer_1)\n",
    "    # (64, 64, 16)\n",
    "\n",
    "    conv2d_layer_2 = Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding = 'same')(conv2d_layer_1)\n",
    "    conv2d_layer_2 = LeakyReLU(alpha=0.3)(conv2d_layer_2)\n",
    "    # (32, 32, 32)\n",
    "\n",
    "    label_layer_3_1 = Dense(32 * 32)(label_layer_2)\n",
    "    label_layer_4_1 = Reshape((32, 32, 1))(label_layer_3_1)\n",
    "    # (32, 32, 1)\n",
    "\n",
    "    concat_layer_1 = Concatenate()([conv2d_layer_2, label_layer_4_1])\n",
    "    # (32, 32, 33)\n",
    "\n",
    "    conv2d_layer_3 = Conv2D(filters = 64, kernel_size = (3,3),  strides = (2,2), padding = 'same')(concat_layer_1)\n",
    "    conv2d_layer_3 = LeakyReLU(alpha=0.3)(conv2d_layer_3)\n",
    "    # (16, 16, 64)\n",
    "\n",
    "    conv2d_layer_4 = Conv2D(filters = 128, kernel_size = (3,3), strides = (2,2), padding = 'same')(conv2d_layer_3)\n",
    "    conv2d_layer_4 = LeakyReLU(alpha=0.3)(conv2d_layer_4)\n",
    "    # (8, 8, 128)\n",
    "\n",
    "    conv2d_layer_5 = Conv2D(filters = 256, kernel_size = (3,3), strides = (2,2), padding = 'same')(conv2d_layer_4)\n",
    "    conv2d_layer_5 = LeakyReLU(alpha=0.3)(conv2d_layer_5)\n",
    "    # (4, 4, 256)\n",
    "\n",
    "    flatten_layer = Flatten()(conv2d_layer_5)\n",
    "    # (4 * 4 * 256)\n",
    "\n",
    "    dropout_layer = Dropout(rate=0.4)(flatten_layer)\n",
    "    # (4 * 4 * 256)\n",
    "\n",
    "    dense_layer = Dense(128 * 8 * 2, activation='relu')(dropout_layer)\n",
    "    # (8 * 128 * 2)\n",
    "\n",
    "    # final layer\n",
    "    output_layer = Dense(1, activation='linear')(dense_layer)\n",
    "    # (1,)\n",
    "\n",
    "    model = Model([input_image,label_layer_1], output_layer)\n",
    "\n",
    "    opt = Adam(learning_rate= 3e-4, beta_1=0.5)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "a = define_discriminator()\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:42.562598Z",
     "iopub.status.busy": "2022-08-23T03:59:42.561478Z",
     "iopub.status.idle": "2022-08-23T03:59:43.754788Z",
     "shell.execute_reply": "2022-08-23T03:59:43.753678Z",
     "shell.execute_reply.started": "2022-08-23T03:59:42.562555Z"
    },
    "id": "f4D-H0p65xNd",
    "outputId": "7873da65-5c5a-4902-9bcb-8c638573ff0a"
   },
   "outputs": [],
   "source": [
    "# plot the discriminator model\n",
    "tf.keras.utils.plot_model(a,to_file='discriminator.png',show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "As6FQBwl6jjG"
   },
   "source": [
    "## **Generator** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:43.757686Z",
     "iopub.status.busy": "2022-08-23T03:59:43.756563Z",
     "iopub.status.idle": "2022-08-23T03:59:44.001844Z",
     "shell.execute_reply": "2022-08-23T03:59:44.000644Z",
     "shell.execute_reply.started": "2022-08-23T03:59:43.757646Z"
    },
    "id": "0GfMsg2WTJUK",
    "outputId": "bad411c1-4ec9-4b0d-de76-fec6dd9396a7"
   },
   "outputs": [],
   "source": [
    "def define_generator(latent_dim = 100, n_classes = 7):\n",
    "\n",
    "    # input level\n",
    "    label_layer_1 = Input(shape=(1,), name = \"input_label\")\n",
    "    label_layer_2 = Embedding(n_classes, 200)(label_layer_1)\n",
    "    label_layer_3 = Dense(8 * 8)(label_layer_2)\n",
    "    label_layer_4 = Reshape((8, 8, 1))(label_layer_3)\n",
    "    # (8, 8, 1)\n",
    "\n",
    "    # latent input\n",
    "    latent_layer = Input(shape=(latent_dim,), name = \"input_latent\")\n",
    "\n",
    "    layer_2 = Dense(128 * 8 * 8)(latent_layer)\n",
    "    layer_2 = Activation(\"relu\")(layer_2)\n",
    "    layer_2 = Reshape((8, 8, 128))(layer_2)\n",
    "    layer_2_1 = BatchNormalization(momentum = 0.8)(layer_2)\n",
    "    # (8, 8, 128)\n",
    "\n",
    "\n",
    "    concat_layer_1 = Concatenate()([layer_2_1, label_layer_4])\n",
    "    # (8, 8, 129)\n",
    "\n",
    "    layer_3 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(concat_layer_1)\n",
    "    layer_3 = Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer = initializers.RandomNormal(0,0.8))(layer_3)\n",
    "    layer_3 = BatchNormalization(momentum = 0.8)(layer_3)\n",
    "    layer_3 = LeakyReLU(alpha=0.4)(layer_3)\n",
    "    # (16, 16, 64)\n",
    "\n",
    "    layer_4 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(layer_3)\n",
    "    layer_4 = Conv2D(filters = 64, kernel_size = (3,3), padding='same',kernel_initializer = initializers.RandomNormal(0,0.8))(layer_4)\n",
    "    layer_4 = BatchNormalization(momentum = 0.8)(layer_4)\n",
    "    layer_4 = LeakyReLU(alpha=0.4)(layer_4)\n",
    "    # (32, 32, 64)\n",
    "\n",
    "    # label_layer_2_1 = Embedding(n_classes, 100)(label_layer_1)\n",
    "    label_layer_3_1 = Dense(32 * 32)(label_layer_2)\n",
    "    label_layer_4_1 = Reshape((32, 32, 1))(label_layer_3_1)\n",
    "    # label_layer_5_1 = BatchNormalization(momentum = 0.8)(label_layer_4_1)\n",
    "    # (32, 32, 1)\n",
    "\n",
    "    concat_layer_2 = Concatenate()([layer_4, label_layer_4_1])\n",
    "    # (32, 32, 65)\n",
    "\n",
    "\n",
    "    layer_5 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(concat_layer_2)\n",
    "    layer_5 = Conv2D(filters = 64, kernel_size = (3,3), padding='same',kernel_initializer = initializers.RandomNormal(0,0.8))(layer_5)\n",
    "    layer_5 = BatchNormalization(momentum = 0.8)(layer_5)\n",
    "    layer_5 = LeakyReLU(alpha=0.4)(layer_5)\n",
    "    # (64, 64, 64)\n",
    "\n",
    "    layer_6 = Conv2DTranspose(filters = 64, kernel_size = (3,3), strides=(2,2), padding='same')(layer_5)\n",
    "    layer_6 = Conv2D(filters = 64, kernel_size = (3,3), padding='same',kernel_initializer = initializers.RandomNormal(0,0.8))(layer_6)\n",
    "    layer_6 = BatchNormalization(momentum = 0.8)(layer_6)\n",
    "    layer_6 = LeakyReLU(alpha=0.4)(layer_6)\n",
    "    # (128, 128, 64)\n",
    "\n",
    "    # final layer\n",
    "    output_layer = Conv2D(filters = 3, kernel_size = (3,3), strides=(1,1), activation='tanh', padding='same')(layer_6)\n",
    "\n",
    "    model = Model([latent_layer,label_layer_1], output_layer)\n",
    "    return model\n",
    "\n",
    "b = define_generator(512)\n",
    "b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:44.004185Z",
     "iopub.status.busy": "2022-08-23T03:59:44.003525Z",
     "iopub.status.idle": "2022-08-23T03:59:44.494492Z",
     "shell.execute_reply": "2022-08-23T03:59:44.493476Z",
     "shell.execute_reply.started": "2022-08-23T03:59:44.004147Z"
    },
    "id": "uOab7yJz55vE",
    "outputId": "181847e5-fbe8-4413-8bce-f0b42e3e12d1"
   },
   "outputs": [],
   "source": [
    "# plot the generator model\n",
    "tf.keras.utils.plot_model(b,to_file='generator.png',show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K74ltFTw63K_"
   },
   "source": [
    "## **Combine** or **GAN** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:44.497287Z",
     "iopub.status.busy": "2022-08-23T03:59:44.496233Z",
     "iopub.status.idle": "2022-08-23T03:59:44.593246Z",
     "shell.execute_reply": "2022-08-23T03:59:44.592161Z",
     "shell.execute_reply.started": "2022-08-23T03:59:44.497248Z"
    },
    "id": "KmspouGiTLhn",
    "outputId": "e8e5585f-27a1-4e26-96c3-cc4a4b40261b"
   },
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "\n",
    "  d_model.trainable = False\n",
    "\n",
    "  g_latent, g_label = g_model.input\n",
    "  g_output = g_model.output\n",
    "\n",
    "  d_output = d_model([g_output,g_label])\n",
    "\n",
    "  model = Model([g_latent, g_label], d_output)\n",
    "\n",
    "  opt = Adam(learning_rate= 3e-4, beta_1=0.5)\n",
    "  model.compile(loss='mse', optimizer=opt,  metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "c = define_gan(b, a)\n",
    "c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:44.598600Z",
     "iopub.status.busy": "2022-08-23T03:59:44.598273Z",
     "iopub.status.idle": "2022-08-23T03:59:45.060090Z",
     "shell.execute_reply": "2022-08-23T03:59:45.059011Z",
     "shell.execute_reply.started": "2022-08-23T03:59:44.598569Z"
    },
    "id": "Zuaon8Y75-Ps",
    "outputId": "fdef1f99-6ab9-497d-e36c-5f5f76368350"
   },
   "outputs": [],
   "source": [
    "# plot GAN model\n",
    "tf.keras.utils.plot_model(c,to_file='complete_gan.png',show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgckUXEo7DxG"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.063252Z",
     "iopub.status.busy": "2022-08-23T03:59:45.061997Z",
     "iopub.status.idle": "2022-08-23T03:59:45.071454Z",
     "shell.execute_reply": "2022-08-23T03:59:45.069603Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.063211Z"
    },
    "id": "VhzajBRw4wxU"
   },
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "  # load dataset\n",
    "  data = np.load(\"../input/celebdataset/celeb_dataset_128.npz\")\n",
    "  data = data['arr_0']\n",
    "  data = np.array(data)\n",
    "  X = data.astype('float32')\n",
    "  # scale from [0,255] to [-1,1]\n",
    "  X = (X - 127.5) / 127.5\n",
    "  return X\n",
    "# k = load_real_samples()\n",
    "# print(\"image: \",k.shape)\n",
    "# print(\"\\nshape/size of the first 16 data: \",k[:16].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDrk7zuwJoN9"
   },
   "source": [
    "## Plot data with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.074207Z",
     "iopub.status.busy": "2022-08-23T03:59:45.073296Z",
     "iopub.status.idle": "2022-08-23T03:59:45.081302Z",
     "shell.execute_reply": "2022-08-23T03:59:45.079931Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.074170Z"
    },
    "id": "ADMcakmWTN60"
   },
   "outputs": [],
   "source": [
    "def save_plot(x_input,n=4):\n",
    "    for i in range(n*n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.imshow(x_input[i,:,:,:])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "# plot data\n",
    "# save_plot(k[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcmHiLEK8HQP"
   },
   "source": [
    "## Generate real sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.083958Z",
     "iopub.status.busy": "2022-08-23T03:59:45.083240Z",
     "iopub.status.idle": "2022-08-23T03:59:45.091402Z",
     "shell.execute_reply": "2022-08-23T03:59:45.090319Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.083920Z"
    },
    "id": "uR1tkpInTQq4"
   },
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "\timages = dataset\n",
    "\tix = randint(0, images.shape[0], n_samples)\n",
    "\tX = images[ix]\n",
    "\tz = np.random.randint(0,7,size=(n_samples))\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn [X,z], y\n",
    "# d = generate_real_samples(k, 32)\n",
    "# print(\"Generate real data as a batch randomly: \",d[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MQHAJ0P8kPF"
   },
   "source": [
    "## Generate latent point function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.093947Z",
     "iopub.status.busy": "2022-08-23T03:59:45.093254Z",
     "iopub.status.idle": "2022-08-23T03:59:45.100540Z",
     "shell.execute_reply": "2022-08-23T03:59:45.099436Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.093895Z"
    },
    "id": "Fv9g2IJXTSpw"
   },
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "  x_input = randn(latent_dim * n_samples)\n",
    "  z_input = x_input.reshape(n_samples, latent_dim)\n",
    "  z = np.random.randint(0,7,size=(n_samples))\n",
    "  return [z_input,z]\n",
    "# p = generate_latent_points(512, 32)\n",
    "# print(\"Generate latent point(with label) as a batch: \",p[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IAEwd9V9GsR"
   },
   "source": [
    "## Generate Fake samples of image with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.103042Z",
     "iopub.status.busy": "2022-08-23T03:59:45.102301Z",
     "iopub.status.idle": "2022-08-23T03:59:45.110170Z",
     "shell.execute_reply": "2022-08-23T03:59:45.109075Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.103003Z"
    },
    "id": "qTcS-0Ou42nA"
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\tz_input,z = generate_latent_points(latent_dim, n_samples)\n",
    "\timages = generator.predict([z_input,z])\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn [images, z], y\n",
    "# with tf.device(device_name):\n",
    "\t# kh = generate_fake_samples(b, 512, 32)\n",
    "\t# print(\"shape of the generated images: \",kh[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Pb6LIHF9mZM"
   },
   "source": [
    "## Summarize the generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.112306Z",
     "iopub.status.busy": "2022-08-23T03:59:45.111782Z",
     "iopub.status.idle": "2022-08-23T03:59:45.121930Z",
     "shell.execute_reply": "2022-08-23T03:59:45.120830Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.112269Z"
    },
    "id": "7c0-Luo746t2"
   },
   "outputs": [],
   "source": [
    "def summarize_the_model(generator,latent_dim = 100):\n",
    "    latent_points = generate_latent_points(latent_dim= latent_dim, n_samples= 16)\n",
    "    X  = generator.predict(latent_points)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    save_plot(X, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.124330Z",
     "iopub.status.busy": "2022-08-23T03:59:45.123862Z",
     "iopub.status.idle": "2022-08-23T03:59:45.133191Z",
     "shell.execute_reply": "2022-08-23T03:59:45.132153Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.124252Z"
    },
    "id": "AgkghuoxJMqv"
   },
   "outputs": [],
   "source": [
    "def save_figure(generator,a,latent_dim = 512,n=4):\n",
    "    latent_points, labels = generate_latent_points(latent_dim= latent_dim, n_samples= 16)\n",
    "    X  = generator.predict([latent_points, labels])\n",
    "    # plt.title(\"Epoch_\"+str(a+1),loc = \"center\")\n",
    "    for j in range(n*n):\n",
    "        plt.subplot(n, n, j+1)\n",
    "        plt.imshow(X[j,:,:,:])\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Epoch_\"+str(a+1))\n",
    "    # plt.savefig(\"/content/drive/MyDrive/GAN_New_Approch/4/epoch_\"+str(a+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWKEC8MA9tGE"
   },
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.136264Z",
     "iopub.status.busy": "2022-08-23T03:59:45.135632Z",
     "iopub.status.idle": "2022-08-23T03:59:45.150038Z",
     "shell.execute_reply": "2022-08-23T03:59:45.149001Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.136239Z"
    },
    "id": "VtrEiQruSiOE"
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim= 100, n_epochs=3, n_batch=128):\n",
    "\n",
    "  print(\"No. of epoch: \",n_epochs)\n",
    "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "  print(\"Data Size: \",dataset.shape[0])\n",
    "  print(\"batch per epoch: \", bat_per_epo)\n",
    "  print(\"full batch: \",n_batch)\n",
    "  half_batch = int(n_batch / 2)\n",
    "  print(\"half batch: \", half_batch,'\\n')\n",
    "  print(\"*\"*50,'\\n\\n')\n",
    "\n",
    "  d_loss_real_array,d_loss_fake_array =[],[]\n",
    "  g_loss_array = []\n",
    "  for i in range(n_epochs):\n",
    "    d_loss_r,d_loss_f = 0.0,0.0\n",
    "    g_loss = 0.0\n",
    "    \n",
    "    for j in range(bat_per_epo):\n",
    "\n",
    "      [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "      d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "      d_loss_r += (d_loss1 / half_batch)\n",
    "      # print(\"real_loss\")\n",
    "\n",
    "      [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "      d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "      d_loss_f += (d_loss2 / half_batch)\n",
    "      # print(\"fake_loss\")\n",
    "\n",
    "      [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "      y_gan = ones((n_batch, 1))\n",
    "      g_loss1,_ = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "      g_loss += (g_loss1 / n_batch)\n",
    "\n",
    "    d_loss_real_array.append(d_loss_r/bat_per_epo)\n",
    "    d_loss_fake_array.append(d_loss_f/bat_per_epo)\n",
    "    g_loss_array.append(g_loss/bat_per_epo)\n",
    "\n",
    "    print('epoch -> [%d/%d], discriminator_loss_for_real_data = %f, discriminator_loss_for_fake_data = %f, generator_loss = %f' %(i+1, n_epochs, d_loss_r/bat_per_epo, d_loss_f/bat_per_epo, g_loss/bat_per_epo))\n",
    "    if((i+1)%10==0):\n",
    "        summarize_the_model(g_model,latent_dim)\n",
    "    g_model.save(\"generator_model.h5\")\n",
    "    np.savez_compressed('loss_record.npz', a=d_loss_real_array, b=d_loss_fake_array, c=g_loss_array)\n",
    "    # save_figure(g_model,i,latent_dim = 512,n=4)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "  return d_loss_real_array, d_loss_fake_array, g_loss_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsaXTk2x987F"
   },
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T03:59:45.152399Z",
     "iopub.status.busy": "2022-08-23T03:59:45.151860Z",
     "iopub.status.idle": "2022-08-23T06:43:44.205096Z",
     "shell.execute_reply": "2022-08-23T06:43:44.204100Z",
     "shell.execute_reply.started": "2022-08-23T03:59:45.152363Z"
    },
    "id": "gMtQt5LfTY82",
    "outputId": "e1bf26fc-e7c8-4ddd-b5e8-0b5a4241dba3"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "  latent_dim = 512\n",
    "  n_epochs = 200\n",
    "  n_batch = 32\n",
    "  d_model = define_discriminator()\n",
    "  g_model = define_generator(latent_dim)\n",
    "  gan_model = define_gan(g_model, d_model)\n",
    "  dataset = load_real_samples()\n",
    "  print('\\nREADY TO GO !!!\\n')\n",
    "  \n",
    "  d_loss_real_array, d_loss_fake_array, g_loss_array = train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWkVxCBlxi3p"
   },
   "source": [
    "## Plot Loss Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.207836Z",
     "iopub.status.busy": "2022-08-23T06:43:44.207142Z",
     "iopub.status.idle": "2022-08-23T06:43:44.212500Z",
     "shell.execute_reply": "2022-08-23T06:43:44.211464Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.207797Z"
    },
    "id": "L3aWl3VFrPaZ"
   },
   "outputs": [],
   "source": [
    "# g_model.save(\"/content/sample_data/generator_model_c_dcgan.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.214428Z",
     "iopub.status.busy": "2022-08-23T06:43:44.214062Z",
     "iopub.status.idle": "2022-08-23T06:43:44.222877Z",
     "shell.execute_reply": "2022-08-23T06:43:44.221833Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.214395Z"
    },
    "id": "1EaPyJ2PKh_Y",
    "outputId": "d875b8e0-cab4-4ec6-c213-625cb53958ea"
   },
   "outputs": [],
   "source": [
    "# loaded = np.load('/content/drive/MyDrive/GAN_New_Approch/4/loss_record_4.npz')\n",
    "# print(loaded['a'].shape)\n",
    "# print(loaded['b'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.225039Z",
     "iopub.status.busy": "2022-08-23T06:43:44.224596Z",
     "iopub.status.idle": "2022-08-23T06:43:44.231194Z",
     "shell.execute_reply": "2022-08-23T06:43:44.230012Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.225004Z"
    },
    "id": "DPUEiC7tx4if"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# d_loss = np.array(loaded['a'])\n",
    "# g_loss = np.array(loaded['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.233319Z",
     "iopub.status.busy": "2022-08-23T06:43:44.232923Z",
     "iopub.status.idle": "2022-08-23T06:43:44.240836Z",
     "shell.execute_reply": "2022-08-23T06:43:44.239527Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.233279Z"
    },
    "id": "zw228YsVuN0O"
   },
   "outputs": [],
   "source": [
    "d_loss = np.array([(i+j) for i,j in zip(d_loss_real_array, d_loss_fake_array)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.243032Z",
     "iopub.status.busy": "2022-08-23T06:43:44.242656Z",
     "iopub.status.idle": "2022-08-23T06:43:44.248887Z",
     "shell.execute_reply": "2022-08-23T06:43:44.247736Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.243000Z"
    },
    "id": "oMK7DxoPuGxL"
   },
   "outputs": [],
   "source": [
    "g_loss = g_loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.251704Z",
     "iopub.status.busy": "2022-08-23T06:43:44.250506Z",
     "iopub.status.idle": "2022-08-23T06:43:44.596663Z",
     "shell.execute_reply": "2022-08-23T06:43:44.595738Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.251668Z"
    },
    "id": "s5qYW8JZxlWt",
    "outputId": "1c26f9b3-8546-4cb9-c03e-06cb7c0101ae"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(d_loss)\n",
    "plt.title('Discriminator Loss Graph')\n",
    "plt.ylabel('Discriminator Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend([\"Discriminator Loss\"], loc='upper right')\n",
    "plt.savefig(\"Discriminator_Loss_Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.598905Z",
     "iopub.status.busy": "2022-08-23T06:43:44.598063Z",
     "iopub.status.idle": "2022-08-23T06:43:44.922832Z",
     "shell.execute_reply": "2022-08-23T06:43:44.921896Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.598867Z"
    },
    "id": "Kla0HPDNymA1",
    "outputId": "249eeedc-10b2-4c67-e3d8-749dd32aa295"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(g_loss,color='orange')\n",
    "plt.title('Generator Loss Graph')\n",
    "plt.ylabel('Generator Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend([\"Generator Loss\"], loc='upper right')\n",
    "plt.savefig(\"Generator_Loss_Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:44.925432Z",
     "iopub.status.busy": "2022-08-23T06:43:44.924810Z",
     "iopub.status.idle": "2022-08-23T06:43:45.263913Z",
     "shell.execute_reply": "2022-08-23T06:43:45.262876Z",
     "shell.execute_reply.started": "2022-08-23T06:43:44.925395Z"
    },
    "id": "Eaf2HX2i0MV3",
    "outputId": "49300bf5-5e84-4476-fd05-83c099b4c24e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(d_loss)\n",
    "plt.plot(g_loss)\n",
    "plt.title('Loss Graph')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend([\"Discriminator Loss\", \"Generator Loss\"], loc='lower right')\n",
    "plt.savefig(\"Loss_Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzogkr9dAr6c"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:45.269504Z",
     "iopub.status.busy": "2022-08-23T06:43:45.269187Z",
     "iopub.status.idle": "2022-08-23T06:43:45.274191Z",
     "shell.execute_reply": "2022-08-23T06:43:45.273029Z",
     "shell.execute_reply.started": "2022-08-23T06:43:45.269476Z"
    },
    "id": "SGdHt4FStkL5",
    "outputId": "1fd07782-e63e-4874-b3f8-8be1218fe548"
   },
   "outputs": [],
   "source": [
    "# generator = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/GAN_New_Approch/4/generator_model_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T06:43:45.276461Z",
     "iopub.status.busy": "2022-08-23T06:43:45.275602Z",
     "iopub.status.idle": "2022-08-23T06:43:45.284632Z",
     "shell.execute_reply": "2022-08-23T06:43:45.283427Z",
     "shell.execute_reply.started": "2022-08-23T06:43:45.276414Z"
    },
    "id": "3gsO4c2O7iCX",
    "outputId": "4f83404c-3405-4e06-cd36-3bfec88e24ec"
   },
   "outputs": [],
   "source": [
    "# latent_dim = 512\n",
    "# n_samples = 16\n",
    "# z_input, labels = generate_latent_points(latent_dim, n_samples)\n",
    "# print(\"latent points(latent points and labels): \",z_input.shape, labels.shape)\n",
    "# data = [z_input,labels]\n",
    "# pred = generator.predict(data)\n",
    "# # pred = (pred +1 ) / 2.0\n",
    "# print(\"\\nGenerated images with labels: \",pred.shape,'\\n')\n",
    "# save_plot(pred,n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDpQNj8x8IsM"
   },
   "source": [
    "                                              -:END:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZoifA0gJLjL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
